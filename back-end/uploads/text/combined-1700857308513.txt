

MODULE 4 Software Project Management - Risk management, Managing people, Teamwork . Project Planning, Software pricing, Plan - driven development, Project scheduling, Agile planning . Estimation techniques, COCOMO cost modeling . Configuration management, Version management, System building, Change management, Release management, Agile software management - SCRUM framework . Kanban methodology and lean approaches . DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Software project management • Software project management is an essential part of software engineering. • Projects need to be managed because professional software engineering is always subject to  organizational budget and schedule constraints.  • The project manager’s job is to ensure that the software project meets and overcomes these  constraints as well as delivering high - quality software.  • Good management cannot guarantee project success.  • However, bad management usually results in project failure: The software may be delivered late,  cost more than originally estimated, or fail to meet the expectations of customers.  • The success criteria for project management obviously vary from project to project, but, for most  projects, important goals are: ■ to deliver the software to the customer at the agreed time;  ■ to keep overall costs within budget;  ■ to deliver software that meets the customer’s expectations;  ■ to maintain a coherent and well - functioning development team. These goals are not unique to software engineering but are the goals of all engineering projects. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Software project management • software engineering is different from other types of engineering in a number of  ways that make software management particularly challenging. Some of these  differences are:  1. The product is intangible : Software is intangible. It cannot be seen or touched.  Software project managers cannot see progress by looking at the artifact that is  being constructed. Rather, they rely on others to produce evidence that they  can use to review the progress of the work.  2. Large software projects are often “one - off” projects: Every large software  development project is unique because every environment where software is  developed is, in some ways, different from all others. 3. Software processes are variable and organization - specific: Different companies  use quite different software development processes. We cannot reliably  predict when a particular software process is likely to lead to development  problems.  DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Software project management It is impossible to write a standard job description for a software project manager. Some of the most  important factors that affect  how software projects are managed are : 1. Company size :  Small companies can operate with informal management and team communications and do not need formal  policies and management structures. In  larger organizations, management hierarchies, formal reporting and budgeting, and  approval processes must be followed.  2. Software customers : If the customer is an  internal customer , then customer communications can be informal and there is no  need to fit in with the customer’s ways of working. If custom software is being developed for an  external customer , agreement  has to be reached on more formal communication channels. If the customer is a  government agency , the software company  must operate according to the agency’s policies and procedures, which are likely to be bureaucratic. 3. Software size :  Small systems  can be developed by a small team, which can get together in the same room to discuss progress  and other management issues.  Large systems  usually need multiple development teams that may be geographically distributed  and in different companies. The project manager has to coordinate the activities of these teams and arrange for them to  communicate with each other.  4. Software type : If the software being developed is a  consumer product , formal records of project management decisions are  unnecessary. On the other hand, if a  safety - critical system  is being developed, all project management decisions should be  recorded and justified as these may affect the safety of the system.  5. Organizational culture : Some organizations have a culture that is based on supporting and encouraging individuals, while  others are group focused. Large organizations are often bureaucratic. Some organizations have a culture of taking risks,  whereas others are risk averse.  6. Software development processes:   Agile processes  typically try to operate with “lightweight” management. More  formal  processes  require management monitoring to ensure that the development team is following the defined process. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Software project management • A number of  fundamental project management activities  are  common to all organizations :  1. Project planning :  Project managers are responsible for planning, estimating, and scheduling project development and  assigning people to tasks. They supervise the work to ensure that it is carried out to the required standards, and they monit or  progress to check that the development is on time and within budget. 2. Risk management : Project managers have to assess the risks that may affect a project, monitor these risks, and take action  when problems arise.  3. People management : Project managers are responsible for managing a team of people. They have to choose people for their  team and establish ways of working that lead to effective team performance. 4. Reporting :  Project managers are usually responsible for reporting on the progress of a project to customers and to the  managers of the company developing the software. They have to be able to communicate at a range of levels, from detailed  technical information to management summaries. They have to write concise, coherent documents that abstract critical  information from detailed project reports. They must be able to present this information during progress reviews.  5. Proposal writing : The first stage in a software project may involve writing a proposal to win a contract to carry out an item of  work. The proposal describes the objectives of the project and how it will be carried out. It usually includes cost and sched ule estimates and justifies why the project contract should be awarded to a particular organization or team. Proposal writing is  a  critical task as the survival of many software companies depends on having enough proposals accepted and contracts awarded. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk management Risk identification Risk analysis Risk planning Risk monitoring DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk management • Risk management is one of the most important jobs for a project manager.  • You can think of a risk as something that you’d prefer not to have happen.  • Risks may threaten the project, the software that is being developed, or the organization.  • Risk management involves anticipating risks that might affect the project schedule or the  quality of the software being developed, and then taking action to avoid these risks. • Risks can be categorized according to  type of risk  (technical, organizational, etc.). • A complementary classification is to  classify risks according to what these risks affect :  1. Project risks: affect the project schedule or resources. An example of a project risk is the loss of  an experienced system architect.  2. Product risks: affect the quality or performance of the software being developed. An example  of a product risk is the failure of a purchased component to perform as expected. This may  affect the overall performance of the system so that it is slower than expected. 3. Business risks: affect the organization developing or procuring the software. For example, a  competitor introducing a new product is a business risk • These risk categories overlap.  DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk management • For  large projects , you should record the results of the risk analysis in  a risk register along with a consequence analysis.  • This sets out the consequences of the risk for the project, product,  and business. • Effective risk management makes it easier to cope with problems and  to ensure that these do not lead to unacceptable budget or schedule  slippage.  • For  small projects , formal risk recording may not be required, but the  project manager should be aware of them. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk management • T he specific risks that may affect a project depend on the project and the organizational environment in which the software is being developed . • However, there are also common risks that are independent of the type of software being developed . • These can occur in any software development project . Some examples of these common risks are shown in Figure . DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk management • Software risk management is important because of the inherent  uncertainties in software development. • These uncertainties stem from loosely defined requirements,  requirements changes due to changes in customer needs, difficulties  in estimating the time and resources required for software  development, and differences in individual skills.  • You have to anticipate risks, understand their impact on the project,  the product, and the business, and take steps to avoid these risks. • You may need to draw up contingency plans so that, if the risks do  occur, you can take immediate recovery action. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk management An  outline of the process of risk management  is presented in Figure. It involves  several stages: 1.  Risk identification : You should identify possible project, product, and business  risks.  2.  Risk analysis : You should assess the likelihood and consequences of these risks.  3.  Risk planning : You should make plans to address the risk, either by avoiding it or by  minimizing its effects on the project.  4.  Risk monitoring : You should regularly assess the risk and your plans for risk  mitigation and revise these plans when you learn more about the risk Figure: The risk management  process DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk management • For large projects, you should document the outcomes of the risk  management process in a risk management plan. • The risk management process is an iterative process that continues  throughout a project.  • Once you have drawn up an initial risk management plan, you monitor the  situation to detect emerging risks. • As more information about the risks becomes  vailable , you have to re - analyze the risks and decide if the risk priority has changed. You may then  have to change your plans for risk avoidance and contingency  management. • Risk management in agile development is less formal. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk identification • Risk identification is the first stage of the risk management process.  • It is concerned with identifying the risks that could pose a major threat to the software engineering process,  the software being developed, or the development organization.  • Risk identification may be a team process in which a team gets together to brainstorm possible risks.  • Alternatively, project managers may identify risks based on their experience of what went wrong on previous  projects. • As a starting point for risk identification, a checklist of different types of risk may be used. Six types of risk  may be included in a risk checklist:  1. Estimation risks: arise from the management estimates of the resources required to build the system.  2. Organizational risks: arise from the organizational environment where the software is being developed.  3. People risks: are associated with the people in the development team.  4. Requirements risks: come from changes to the customer requirements and the process of managing the  requirements change.  5. Technology risks: come from the software or hardware technologies that are used to develop the system. 6. Tools risks: come from the software tools and other support software used to develop the system DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk identification Figure 1: Examples of different types  of risks DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk identification • When you have finished the risk identification process, you should  have a long list of risks that could occur and that could affect the  product, the process, and the business. • You then need to prune this list to a manageable size. If you have too  many risks, it is practically impossible to keep track of all of them DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk analysis • During the risk analysis process, you have to consider each identified risk and make a  judgment about the probability and seriousness of that risk.  • You have to rely on your judgment and experience of previous projects and the problems  that arose in them.  • It is not possible to make precise, numeric assessment of the probability and seriousness  of each risk.  • Rather, you should assign the risk to one of a number of bands: 1. The probability of the risk might be assessed as insignificant, low, moderate, high, or  very high.  2. The effects of the risk might be assessed as catastrophic (threaten the survival of the  project), serious (would cause major delays), tolerable (delays are within allowed  contingency), or insignificant. Y Y ou may then tabulate the results of this analysis process using a table ordered according  to the seriousness of the risk. (table in the next slide) DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk analysis Figure 2: Risk types and  examples DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk analysis • B oth the probability and the assessment of the effects of a risk may change  as more information about the risk becomes available and as risk  management plans are implemented.  • Update the risk table during each iteration of the risk management  process.  • Once the risks have been analyzed and ranked, assess which of these risks  are most significant. The judgment must depend on a combination of the  probability of the risk arising and the effects of that risk.  • In general, catastrophic risks should always be considered, as should all  serious risks that have more than a moderate probability of occurrence. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk planning • The risk planning process develops strategies to manage the key risks that threaten the project.  • For each risk, you have to think of actions that you might take to minimize the disruption to the  project if the problem identified in the risk occurs. • You should also think about the information that you need to collect while monitoring the project  so that emerging problems can be detected before they become serious. • In risk planning, you have to ask “what - if” questions that consider both individual risks,  combinations of risks, and external factors that affect these risks.  • For example, questions that you might ask are:  1. What if several engineers are ill at the same time?  2. What if an economic downturn leads to budget cuts of 20% for the project? 3. What if the performance of open - source software is inadequate and the only expert on that  open - source software leaves?  4. What if the company that supplies and maintains software components goes out of business?  5. What if the customer fails to deliver the revised requirements as predicted?  DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk planning Based on the answers to these “what - if” questions, you may devise strategies for managing the  risks. These strategies fall into three categories:  1. Avoidance strategies: Following these strategies means that the probability that the risk will  arise is reduced. An example of a risk avoidance strategy is the strategy for dealing with  defective components shown in figure 3. 2. Minimization strategies :Following these strategies means that the impact of the risk is  reduced. An example of a risk minimization strategy is the strategy for staff illness shown in  Figure 3 3. Contingency plans: Following these strategies means that you are prepared for the worst and  have a strategy in place to deal with it. An example of a contingency strategy is the strategy for  organizational financial problems shown in Figure 3. Figure 3 shows possible risk management strategies that have been identified for the key risks (i.e.,  those that are serious or intolerable)  durig the previous phase(risk analysis)(figure 2). DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk planning Figure 3: Strategies to help  manage risks DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk monitoring • Risk monitoring is the process of checking that your assumptions about the  product, process, and business risks have not changed.  • You should regularly assess each of the identified risks to decide whether  or not that risk is becoming more or less probable. • You should also think about whether or not the effects of the risk have  changed.  • To do this, you have to look at other factors, such as the number of  requirements change requests, which give you clues about the risk  probability and its effects. These factors are obviously dependent on the  types of risk. • Figure 4 gives some examples of factors that may be helpful in assessing  these risk types. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Risk monitoring Figure 4: Risk indicators DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Managing people Motivating people DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Managing people • The people working in a software organization are its greatest assets. • It is expensive to recruit and retain good people, and it is up to  software managers to ensure that the engineers working on a project  are as productive as possible. • It is important that software project managers understand the  technical issues that influence the work of software development. • As a project manager, you should be aware of the potential problems  of people management and should try to develop people  management skills. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Managing people • There are four critical factors that influence the relationship between a  manager and the people that he or she manages:  1. Consistency: All the people in a project team should be treated in a  comparable way.  2. Respect: Different people have different skills, and managers should  respect these differences. All members of the team should be given an  opportunity to make a contribution. 3. Inclusion: It is important to develop a working environment where all  views, even those of the least experienced staff, are considered. 4. Honesty: As a manager, you should always be honest about what is going  well and what is going badly in the team. You should also be honest  about your level of technical knowledge and be willing to defer to staff  with more knowledge when necessary.   DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Motivating people • As a project manager, you need to motivate the people who work with you so  that they will contribute to the best of their abilities. • In practice, motivation means organizing work and its environment to  encourage people to work as effectively as possible.  • If people are not motivated, they will be less interested in the work they are  doing. • people are motivated by satisfying their needs. These needs are arranged in a  series of levels(figure). • The lower levels of this hierarchy represent fundamental needs for food, sleep,  and so on. • Social need is concerned with the need to feel part of a social grouping.  • Esteem need represents the need to feel respected by others, and self - realization need is concerned with personal development.  • People need to satisfy lower - level needs such as hunger before the more  abstract, higher - level needs. Human needs hierarchy DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Motivating people • M aking sure that peoples’ social, esteem, and self - realization needs are  satisfied is most important from a management point of view.  1. To satisfy social needs, you need to give people time to meet their co - workers and provide places for them to meet. 2. To satisfy esteem needs, you need to show people that they are valued  by the organization. 3. Finally, to satisfy self - realization needs, you need to give people  responsibility for their work, assign them demanding (but not  impossible) tasks, and provide opportunities for training and  development where people can enhance their skills. Training is an  important motivating influence as people like to gain new knowledge  and learn new skills. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Motivating people • Psychological personality type also influences motivation. Three classifications for professional  workers are identified: 1. Task - oriented people, who are motivated by the work they do. In software engineering, these  are people who are motivated by the intellectual challenge of software development. 2. Self - oriented people, who are principally motivated by personal success and recognition. They  are interested in software development as a means of achieving their own goals. They often  have longer - term goals, such as career progression, that motivate them, and they wish to be  successful in their work to help realize these goals.  3. Interaction - oriented people, who are motivated by the presence and actions of co - workers.  Research has shown that interaction - oriented personalities usually like to work as part of a group,  whereas task - oriented and self - oriented people usually prefer to act as individuals. Women are  more likely to be interaction - oriented than men are. They are often more effective communicators.  DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Teamwork Selecting group members Group organization Group communications DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Teamwork • Most professional software is developed by project teams that range in size  from two to several hundred people. • However, as it is impossible for everyone in a large group to work together  on a single problem, large teams are usually split into a number of smaller  groups. • Each group is responsible for developing part of the overall system. The  best size for a software engineering group is 4 to 6 members, and they  should never have more than 12 members.  • When groups are small, communication problems are reduced. • Putting together a group that has the right balance of technical skills,  experience, and personalities is a critical management task. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Teamwork • A good group is cohesive and thinks of itself as a strong, single unit. The people  involved are motivated by the success of the group as well as by their own  personal goals.  • In a cohesive group, members think of the group as more important than the  individuals who are group members.  • Members of a well - led, cohesive group are loyal to the group. They identify with  group goals and other group members.  • They attempt to protect the group, as an entity, from outside interference.  • The benefits of creating a cohesive group are:  1. The group can establish its own quality standards  2. Individuals learn from and support each other  3. Knowledge is shared: Continuity can be maintained if a group member leaves.  4. Refactoring and continual improvement is encouraged DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Teamwork • Good project managers should always try to encourage group cohesiveness.  • They may try to establish a sense of group identity by naming the group and establishing a group identity  and territory. • Social events for group members and their families are a good way to bring people together. • One of the most effective ways of promoting cohesion is to be inclusive. That is, you should treat group  members as responsible and trustworthy, and make information freely available. • An effective way of making people feel valued and part of a group is to make sure that they know what is  going on. • Given a stable organizational and project environment, the three factors that have the biggest effect on  team working are:  1. The people in the group: You need a mix of people in a project group as software development involves  diverse activities such as negotiating with clients, programming, testing, and documentation. 2. The way the group is organized :A group should be organized so that individuals can contribute to the  best of their abilities and tasks can be completed as expected.  3. Technical and managerial communications: Good communication between group members, and between  the software engineering team and other project stakeholders, is essential. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Selecting group members • A manager or team leader’s job is to create a cohesive group and organize that group so that they work together effectively.  • This task involves selecting a group with the right balance of technical skills and personalities.  • Sometimes people are hired from outside the organization; more often, software engineering groups are put together from  current employees who have experience on other projects.  • Managers rarely have a completely free hand in team selection.  • They often have to use the people who are available in the company, even if they are not the ideal people for the job. • Technical knowledge and ability should not be the only factor used to select group members.  • The “competing engineers” problem can be reduced if the people in the group have complementary motivations.  • People who are motivated by the work are likely to be the strongest technically.  • People who are self - oriented will probably be best at pushing the work forward to finish the job.  • People who are interaction - oriented help facilitate communications within the group.  • Interaction oriented people like to talk to people and can detect tensions and disagreements at an early stage, before these  problems have a serious impact on the group. • It is sometimes impossible to choose a group with complementary personalities. If this is the case, the project manager has t o  control the group so that individual goals do not take precedence over organizational and group objectives. This control is e asi er to  achieve if all group members participate in each stage of the project DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Group organization • The way a group is organized affects the group’s decisions, the ways  information is exchanged, and the interactions between the development  group and external project stakeholders.  • Important organizational questions for project managers include the  following:  1. Should the project manager be the technical leader of the group? 2. Who will be involved in making critical technical decisions, and how will  these decisions be made?  3. How will interactions with external stakeholders and senior company  management be handled?  4. How can groups integrate people who are not co - located?  5. How can knowledge be shared across the group?  DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Group organization • Small programming groups are usually organized in an informal way. The group leader gets  involved in the software development with the other group members.  • In an informal group, the group as a whole discusses the work to be carried out, and tasks are  allocated according to ability and experience. More senior group members may be responsible for  the architectural design. However, detailed design and implementation is the responsibility of the  team member who is allocated to a particular task. • Agile development teams are always informal groups. • If a group is composed mostly of inexperienced or incompetent members, informality can be a  hindrance. • In hierarchical groups the group leader is at the top of the hierarchy. He or she has more formal  authority than the group members and so can direct their work. There is a clear organizational  structure, and decisions are made toward the top of the hierarchy and implemented by people  lower down. Communications are primarily instructions from senior staff; the people at lower  levels of the hierarchy have relatively little communication with the managers at the upper levels. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Group organization • Hierarchial model rarely works well for complex software engineering. • In software development, effective team communications at all levels is essential:  1. Changes to the software often require changes to several parts of the system,  and this requires discussion and negotiation at all levels in the hierarchy.  2. Software technologies change so fast that more junior staff may know more  about new technologies than experienced staff. Top - down communications may  mean that the project manager does not find out about the opportunities of using  these new technologies. More junior staff may become frustrated because of what  they see as old - fashioned technologies being used for development.  A major challenge facing project managers is the difference in technical ability  between group members.  DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Group communications • It is absolutely essential that group members communicate effectively  and efficiently with each other and with other project stakeholders. • Group members must exchange information on the status of their  work, the design decisions that have been made, and changes to  previous design decisions.  • They have to resolve problems that arise with other stakeholders and  inform these stakeholders of changes to the system, the group, and  delivery plans. • Good communication also helps strengthen group cohesiveness.  DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Group communications • The effectiveness and efficiency of communications are influenced by: 1. Group size: As a group gets bigger, it gets harder for members to communicate effectively. The number of  one - way communication links is n * (n − 1), where n is the group size, so, with a group of eight members,  there are 56 possible communication pathways. This means that it is quite possible that some people will  rarely communicate with each other.  2. Group structure: People in informally structured groups communicate more effectively than people in  groups with a formal, hierarchical structure.  3. Group composition: People with the same personality types may clash, and, as a result, communications  can be inhibited. Communication is also usually better in mixed - sex groups than in single - sex groups.  Women are often more interaction - oriented than men and may act as interaction controllers and  facilitators for the group. 4. The physical work environment: The organization of the workplace is a major factor in facilitating or  inhibiting communications. 5. The available communication channels: There are many different forms of communication — face to face,  email messages, formal documents, telephone, and technologies such as social networking and wikis. As  project teams become increasingly distributed, with team members working remotely, you need to make  use of interaction technologies, such as conferencing systems, to facilitate group communications. DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING
Group communications • Effective communication is achieved when communications are two - way and the  people involved can discuss issues and information and establish a common  understanding of proposals and problems. • All this can be done through meetings, although these meetings are often  dominated by powerful personalities. • Informal discussions when a manager meets with the team for coffee are  sometimes more effective.  • More and more project teams include remote members, which also makes  meetings more difficult.  • To involve them in communications, you may make use of wikis and blogs to  support information exchange.  • Wikis and blogs allow project members and external stakeholders to exchange  information, irrespective of their location.  DEPARTMENT OF CSE, SAINTGITS COLLEGE OF ENGINEERING

MODULE 3 Object - oriented design using the UML, Design patterns, Implementation issues, Open - source development  - Open - source licensing  - GPL, LGPL, BSD. Review Techniques  - Cost impact of Software Defects, Code review and statistical  analysis. Informal Review, Formal Technical Reviews, Post - mortem evaluations. Software testing strategies  - Unit  Testing, Integration Testing, Validation testing, System testing, Debugging, White box testing, Path testing, Control  Structure testing, Black box testing, Testing Documentation and Help facilities. Test automation, Test - driven  development, Security testing. Overview of  DevOps and Code Management  - Code management,  DevOps automation, Continuous Integration, Delivery, and Deployment (CI/CD/CD). Software Evolution  - Evolution  processes, Software maintenance
Object - oriented design using the  UML System context and interactions Architectural design Object class identification Design models Interface specification
Object - oriented design using the UML • An object - oriented system is made up of interacting objects that maintain their own local state  and provide operations on that state.  • Object - oriented design processes involve designing object classes and the relationships between  these classes. These classes define the objects in the system and their interactions.  • When the design is realized as an executing program, the objects are created dynamically from  these class definitions. Objects include both data and operations to manipulate that data. • Because objects are associated with things, there is often a clear mapping between real - world  entities (such as hardware components) and their controlling objects in the system.  • To develop a system design from concept to detailed, object - oriented design, we need to:  1. Understand and define the context and the external interactions with the system.  2. Design the system architecture.  3. Identify the principal objects in the system.  4. Develop design models.  5. Specify interfaces.
System context and interactions • The first stage in any software design process is to develop an understanding of the relationships between the software that  is  being  designed and its external environment.  • This is essential for deciding how to provide the required system functionality and how to structure the system to communicat e w ith its  environment.  • understanding the context also lets you establish the boundaries of the system.  • Setting the system boundaries helps you decide what features are implemented in the system being designed and what features a re  in  other associated systems.  Eg : we need to decide how functionality is distributed between the control system for all of the weather  stations and the embedded software in the weather station itself.  • System context models and interaction models present complementary views of the relationships between a system and its  environment 1. A  system context model  is a structural model that demonstrates the other systems in the environment of the system being developed. 2. An  interaction model  is a dynamic model that shows how the system interacts with its environment as it is used. • The context model of a system may be represented using associations. Associations simply show that there are some relationshi ps  between the entities involved in the association. You can document the environment of the system using a simple block diagram ,  showing the entities in the system and their associations.  • When you model the interactions of a system with its environment, you should use an abstract approach that does not include t oo  much detail. One way to do this is to use a use case model. 
System context and interactions • the weather station interacts with the  weather information system to report  weather data and the status of the weather  station hardware. Other interactions are  with a control system that can issue specific  weather station control commands. The cardinality information on the link shows  that there is a single control system but  several weather stations, one satellite, and  one general weather information system.
System context and interactions • Use case description  – report whether
Architectural design • Once the interactions between the software system and the system’s  environment have been defined, use this information as a basis for  designing the system architecture.  • Combine this knowledge with the general knowledge of the principles  of architectural design and with more detailed domain knowledge.  • Identify the major components that make up the system and their  interactions.  • Design the system organization using an architectural pattern such as a  layered or client – server model. • high - level architectural design for the weather station software is  shown in figure. The weather station is composed of independent  subsystems that communicate by broadcasting messages on a  common infrastructure, shown as communication link in figure • Each subsystem listens for messages on that infrastructure and picks  up the messages that are intended for them. This “ listener model ” is a  commonly used architectural style for distributed system. • When the communications subsystem receives a control command,  such as shutdown, the command is picked up by each of the other  subsystems, which then shut themselves down in the correct way. The  key benefit of this architecture is that it is easy to support different  configurations of subsystems because the sender of a message does  not need to address the message to a particular subsystem • Figure 7.5 shows  the architecture of the data collection subsystem,  which is included in Figure 7.4. The Transmitter and Receiver objects  are concerned with managing communications, and the  WeatherData object encapsulates the information that is  collected  from the  instruments and transmitted to the weather information system.
Object class identification • Some ideas about the essential objects in the system that is  being designed is mandatory. • As the understanding of the design develops, refine these  ideas about the system objects.  • The use case description helps to identify objects and  operations in the system.  • From the description of the Report weather use case, it is  obvious that it is needed to implement objects representing  the instruments that collect weather data and an object  representing the summary of the weather data. You also  usually need a high - level system object or objects that  encapsulate the system interactions defined in the use cases.  With these objects in mind, you can start to identify the  general object classes in the system. various  ways of identifying object classes in object - oriented  systems were suggested:  • 1 . Use a grammatical analysis of a natural language  description of the system to be constructed. Objects and  attributes are nouns; operations or services are verbs  . • 2 . Use tangible entities (things) in the application domain  such as aircraft, roles such as manager, events such as  request, interactions such as meetings, locations such as  offices, organizational units such as companies, and so on  • 3 . Use a scenario - based analysis where various scenarios of  system use are  identified  and analyzed in turn. As each  scenario is analyzed, the team responsible for the analysis  must identify the required objects, attributes, and  operations. several knowledge  sources are used  to discover object classes.  Object classes, attributes, and operations that are initially  identified from the informal system description can be a starting  point for the design. Information from application domain  knowledge or scenario analysis may then be used to refine and  extend the  initial  objects. This information can be collected from  requirements documents,  discussions  with users, or analyses of  existing systems. 
Object class identification • In the wilderness weather station, object identification is based on the tangible hardware in the system . • Five object classes are shown in the figure . • The Ground thermometer, Anemometer, and Barometer objects are application domain objects, and the WeatherStation and WeatherData objects have been identified from the system description and the scenario (use case) description :
Design models • Design models show  the objects or object classes in a system . • They also show the associations and relationships between these entities . • These models are the bridge between the system requirements and the implementation of a system.  • They  have to be abstract so that unnecessary detail doesn’t hide the  relationships  between them and the system requirements.  However, they also have to include enough detail for programmers to make implementation decisions.  • The  level of detail that you need in a design model depends on the design process used.  • Where  there are close links between requirements engineers, designers and programmers, then abstract models may be all that  are required. Specific design decisions may be made as the system is implemented, with problems resolved through informal  discussions. Similarly, if agile development is used, outline design models on a whiteboard may be all that is  required. • if a plan - based development process is used, you may need more detailed models. When the links between requirements  engineers, designers, and  programmers  are indirect (e.g., where a system is being designed in one part of an  organization  but  implemented elsewhere), then precise design descriptions are needed for communication. Detailed models, derived from the  high - level abstract models, are used so that all team members have a common understanding of the  design. • An important step in the design process, therefore, is to decide on the design models that you need and the level of detail  required in these models. This depends on the type of system that is being developed. A sequential data - processing system is qui te  different from an embedded real - time system, so you need to use different types of design models. 
Design models • When  you use the UML to develop a design,  you should develop  two kinds of design  model :  1 .  Structural models , which describe the static  structure of the system using object classes and  their relationships. Important relationships that  may be documented at this stage are  generalization (inheritance) relationships,  uses/used - by relationships, and composition  relationships.  2 .  Dynamic models , which describe the dynamic  structure of the system and show the expected  runtime interactions between the system  objects. Interactions that may be documented  include the sequence of service requests made  by objects and the state changes triggered by  these object interactions Three  UML model types are particularly useful  for adding detail to use case and architectural  models :  1 .  Subsystem models , which show logical  groupings of objects into coherent  subsystems .  These are represented using a form of class  diagram with each subsystem shown as a  package with enclosed objects. Subsystem  models are structural models.  2 .  Sequence models , which show the sequence  of object interactions. These are represented  using a UML sequence or a collaboration  diagram. Sequence models are dynamic models.  3 .  State machine models , which show how  objects change their state in response to events.  These are represented in the UML using state  diagrams. State machine models are dynamic  model
Design models • Sequence  models are dynamic models  that describe, for each mode of  interaction, the sequence of object  interactions that take place.  • When  documenting a design, you  should produce a sequence model for  each significant interaction.  • If  you have  developed  a use case  model, then there should be a  sequence model for each use case that  you have identified Sequence diagram describing data  collection
Design models • Weather station state diagram
Interface specification • An important part of any design process is the specification of the  interfaces between the components in the design.  • We  need to specify interfaces so that objects and subsystems can be  designed in parallel.  • Once  an interface has been specified, the developers of other objects  may assume that interface will be implemented.  • Interface  design is concerned with specifying the detail of the interface  to an object or to a group of objects. This means defining the  signatures and semantics of the services that are provided by the  object or by a group of objects.  • Interfaces  can be specified in the UML using the same notation as a  class diagram. However, there is no attribute section, and the UML  stereotype «interface» should be included in the name part. The  semantics of the interface may be defined using the object constraint  language (OCL).  • Details  of the data  representation should not be included  in an  interface design, as attributes are not defined in an interface  specification. However,  operations  to access and update  data should  be included.  • As  the data representation is hidden, it can be easily changed without  affecting the objects that use that data. This leads to a design that is  inherently more maintainable . • There is not a simple 1:1 relationship between objects and interfaces.  The same object may have several interfaces, each of which is a  viewpoint on the methods that it provides. This is supported directly in  Java, where interfaces are declared separately from objects and  objects “implement” interfaces.  • Equally , a group of objects may all be accessed through a single  interface.  • Figure  shows  two interfaces that may be defined for the weather  station. The  lefthand interface is a reporting interface that defines the  operation names that are used to generate weather and status  reports. These map directly to operations in the  WeatherStation object. The remote control interface provides four operations, which  map onto a single method in the  WeatherStation object. 
Design patterns
Design patterns • The pattern is a description of the problem and the essence of its solution,  so that the solution may be reused in different settings. The pattern is  not  a  detailed  specification. • Patterns have made a huge impact on object - oriented software design. As  well as being tested solutions to common problems, they have become a  vocabulary for  talking  about a design. You can therefore explain your  design by describing the patterns that you have used.  • Patterns  are a way of reusing the knowledge and experience of other  designers. Design patterns are usually associated with object - oriented  design. Published patterns often rely on object characteristics such as  inheritance and polymorphism to provide generality. However, the general  principle of encapsulating experience in a pattern is  one  that is equally  applicable to any kind of software design.
Design patterns The Gang of Four defined the four essential elements of design patterns in their book on  patterns:  1 . A name that is a meaningful reference to the pattern . 2 . A description of the problem area that explains when the pattern may be applied . 3. A solution description of the parts of the design solution, their relationships and their  responsibilities. This is not a concrete design description. It is a template for a design  solution that can be instantiated in different ways. This is often expressed graphically and  shows the relationships between the objects and object classes in the solution.  4 . A statement of the consequences — the results and trade - offs — of applying the pattern.  This can help designers understand whether or not a pattern can be used in a particular  situation.  • Gamma  and his co - authors break down the problem description into motivation (a  description of why the pattern is useful) and applicability (a description of  situations  in  which the pattern may be used). Under the description of the solution, they describe the  pattern structure, participants, collaborations, and implementation.

Design patterns • The above  pattern can be used in situations where different  presentations of an object’s state are required. It separates the object  that must be displayed from the different forms of presentation. This  is illustrated in  the below figure,  which shows two different graphical  presentations of the same  dataset.
Design patterns • Graphical representations are normally used to illustrate the object  classes in patterns and their relationships.  • These  supplement the pattern description and add detail to the  solution description. Figure  shows the  representation in UML of the  Observer pattern
Design patterns • To use patterns in your design, you need to recognize that any design  problem you are facing may have an associated pattern that can be  applied. Examples of such problems, documented in the Gang of Four’s  original patterns book, include:  1 . Tell several objects that the state of some other object has changed  (Observer pattern ). 2. Tidy up the interfaces to a number of related objects that have often been  developed  incrementally (Façade pattern ). 3. Provide a standard way of accessing the elements in a collection,  irrespective of how that collection is implemented (Iterator pattern ). 4. Allow for the possibility of extending the functionality of an existing class  at runtime (Decorator pattern).
Design patterns • Patterns support high - level, concept reuse . • Using patterns means that you reuse the ideas but can adapt the  implementation to suit the system you are developing. • Patterns are a great idea, but you need experience of software design  to use them effectively.
Implementation issues Reuse Configuration management  Host - target  development
Implementation issues • system  implementation  - create  an executable version of the  software . • Implementation may involve developing programs in high - or low - level programming languages or tailoring and adapting generic, off - the - shelf systems to meet the specific requirements of an  organization. • A spects  of implementation that are particularly important to software  engineering: • Reuse • Configuration management  • Host - target development
Reuse • Most modern software is constructed by reusing existing  components  or systems. When you are developing software, you  should make as much use as possible of existing  code. • The only significant reuse or software was the reuse of functions and  objects in programming language libraries.  • A reuse - based approach is now widely used for web - based systems  of all kinds, scientific software, and, increasingly, in embedded  systems engineering
Reuse • Software reuse is possible at a number of different levels, as shown in  Figure
Reuse Different levels of software reuse: 1. The  abstraction  level:  At this level,  we  don’t reuse software directly but rather use knowledge of  successful abstractions in the design of your software. Design patterns and architectural patterns  are  ways of representing abstract knowledge for reuse. 2. The  object  level:  At this level,  we  directly reuse objects from a library rather than writing the code  yourself. To implement this type of reuse, you have to find appropriate libraries and discover if the  objects and methods offer the  functionality  that you  need 3 . The component  level:  Components are collections of objects and object classes that operate  together to provide related functions and services. You often have to adapt and extend the  component by adding some code of your own.  4 . The system  level:  At this level, you reuse entire application systems. This function usually involves  some kind of configuration of these systems. This may be done by adding and modifying code (if you  are reusing a software product line) or by using the system’s own configuration interface. Most  commercial systems are now built in this way where generic application systems  are adapted and  reused. Sometimes this approach may involve integrating several application systems to create a  new system
Reuse costs associated with reuse:  1 . The costs of the time spent in looking for software to reuse and assessing  whether or not it meets your needs. You may have to test the software to make  sure that it will work in your environment, especially if this is different from its  development environment.  2 . Where applicable, the costs of buying the reusable software. For large  off - the  shelf  systems, these costs can be very high.  3 . The costs of adapting and configuring the reusable software components or  systems to reflect the requirements of the system that you are developing.  4 . The costs of integrating reusable software elements with each other (if you are  using software from different sources) and with the new code that you have  developed. Integrating reusable software from different providers can be  difficult  and expensive because the providers may make conflicting assumptions about how  their respective software will be reused.
Configuration management • During the development process, many different versions of each software component  are created.  • If  you don’t keep track of these versions in a configuration management system, you are  liable to include the wrong versions of these components in your system . • change happens all the time, so change management is absolutely essential . • When several people are involved in developing a software  system , you have to make  sure that team members don’t interfere with each other’s  work. • also  have to ensure that everyone can access the most up - to - date  versions  of software  components; otherwise developers may redo work that has already been done.  • Configuration  management is the name given to the general process of managing a  changing software system. The aim of configuration management is to support the  system integration process so that all developers can access the project code and  documents in a controlled way, find out what changes have been made, and compile  and link components to create a system. 
Configuration management • Four  fundamental configuration management activities :
Configuration management Four  fundamental configuration management activities : 1.  Version  management , where support is provided to keep track of the different versions  of software components. Version management systems include facilities to coordinate  development by several programmers. They stop one developer from overwriting code  that has been submitted to the system by someone else . 2.  System  integration , where support is provided to help developers define what versions  of components are used to create each version of a system. This description is then used to  build a system automatically by compiling and  linking  the required  components. 3.  Problem  tracking , where support is provided to allow users to report bugs and other  problems, and to allow all developers to see who is working on these  problems  and when  they are fixed.  4 .  Release management , where new versions of a software system are released to  customers. Release management is concerned with planning the functionality of new  releases and organizing the software for distribution.
Configuration management • Software configuration management tools support each of the above  activities . • These tools are usually installed in an integrated development  environment, such as Eclipse.  • Version  management may be supported using a version management  system such as Subversion  or  Git ,which  can support multi - site, multi - team  development.  • System  integration support may be built into the language or rely on a  separate  toolset  such as the GNU build system.  • Bug  tracking or issue tracking systems, such as  Bugzilla , are used to report  bugs and other issues and to keep track of whether or not these have been  fixed
Host - target development • Production  software does not usually execute on the same computer  as the software development environment.  • Rather , you develop it on one computer (the host system) and  execute it on a separate computer (the target system). The host and  target systems are sometimes of the same type, but often they are  completely different.
Host - target development • Figure : Host target development • Most professional software development is based on a host - target  model.
Host - target development • Software is developed on one computer (the host) but runs on a separate machine (the target).  • More  generally, we can talk about a development platform (host) and an execution platform (target). A platform is more than just  hardware . • It includes the installed operating system plus other supporting software such as a database  management  system or, for  development platforms, an interactive development environment . • Sometimes, the development platform and execution platform are the same,  making  it possible to develop the software and test it  on the same machine. Therefore, if you develop in Java, the target environment is the Java Virtual Machine. In  principle , this is the  same on every computer, so programs should be portable from one machine to another.  • However , particularly for embedded systems and mobile systems, the development and the execution platforms are different. You  need to either move your developed software to the execution platform for testing or run a simulator on your development  machine.  • Simulators  are often used when developing embedded systems. You simulate hardware devices, such as sensors, and the events in  the environment in which the system will be deployed. Simulators speed up the development process for  embedded  systems as  each developer can have his or her own execution platform with no need to download the software to the target hardware.  • However , simulators are expensive to develop and so are usually available only for the most popular hardware architectures. If the  target system has installed middleware or other software that you need to use, then you need to be able to test the system us ing that software . • It may be impractical to install that software on your development machine, even if it is the same as the target platform, be cau se  of license restrictions. If this is the case, you need to transfer your developed code to the execution platform to test the  sys tem
Host - target development A  software development platform should provide a range of tools to support  software  engineering processes.  • These  may include:  1. An  integrated compiler and syntax - directed editing system that allows you to create, edit, and compile code.  2. A  language debugging system.  3. Graphical  editing tools, such as tools to edit UML models.  4. Testing  tools, such as  JUnit , that can automatically run a set of tests on a new version of a program.  5. Tools  to support refactoring and program visualization.  6. Configuration  management tools to manage source code versions and to integrate and build systems.  In  addition to these standard tools, your development system may include more specialized tools such as static analyzers  .  Normally ,  development  environments for teams also include a shared server that runs a change and configuration management  system and, perhaps, a system to support requirements management.  Software  development tools are now usually installed within an integrated  development  environment (IDE). An IDE is a set of  software tools that supports different aspects of software development within some common framework and user  interface .  Generally, IDEs are created to support development in a specific  programming  language  such as Java . A general - purpose IDE is a framework for hosting software tools that provides data management facilities for the software being  developed and integration mechanisms that allow tools to work together. The best - known general - purpose IDE is the Eclipse  environment (http://www.eclipse.org).
Host - target development • you need to make decisions about how the developed software will be deployed on the target platform.  For  distributed systems, you need to decide on the specific platforms where the  components  will be deployed.  Issues that you have to consider in making this decision are : 1. The  hardware and software requirements of a  component:  If a component is designed for a specific  hardware architecture, or relies on some other software system, it must obviously be deployed on a  platform that provides the required hardware and software  support.  2. The  availability requirements of the  system:  High - availability systems may require components to be  deployed on more than one platform. This means that, in the event of platform failure, an alternative  implementation of the component is available.  3. Component communications:  If there is a lot of  intercomponent communication, it is usually best to  deploy them on the same platform or on platforms that are physically close to one another. This reduces  communications latency — the delay between the time that a message is sent by one component and  received by another . You can document your decisions on hardware and software deployment using UML deployment diagrams,  which show how software components are distributed across hardware platforms.  If  you are developing an embedded system, you may have to take into account target characteristics, such as its  physical size, power capabilities, the need for real - time responses to sensor events, the physical characteristics  of actuators and its real - time operating system.
Open - source development Open source development Open source licensing
Open - source development • Open - source development is an approach to software development in which the source code of a software  system is published and volunteers are invited to  participate  in the development process  . • Its  roots are in the Free Software Foundation (www.fsf.org), which advocates that source code should not be  proprietary  but rather should always be available for users to examine and modify as they wish.  • There  was an assumption that the code would be controlled and developed by a small core group, rather  than users of the code. Open - source software extended this idea by using the Internet to recruit a much  larger population of volunteer developers. Many of them are also users of the code. In principle at least, any  contributor to an open - source project may report and fix bugs and propose new features and functionality.  • However , in practice, successful open - source systems still rely on a core group of developers who control  changes to the software . • Open - source software is the backbone of the Internet and software engineering. The Linux operating  system is the most widely used server system, as is the open - source Apache web server. Other important  and universally used open - source products are Java, the Eclipse IDE, and the  mySQL database management  system. The Android operating system is installed on millions of mobile devices. Major players in the  computer  industry such as IBM and Oracle, support the open - source movement and base their software on  open - source products. Thousands of other, lesser - known open - source systems and components may also be  used.
• It is usually cheap or even free to acquire open - source software.  • You  can normally download open - source software without charge.  • However , if you want  documentation  and support, then you may have to  pay for this, but costs are usually fairly low.  • The  other key benefit of using open - source products is that widely used  open - source systems are very reliable . • They have a large population of users who are willing to fix problems  themselves rather than report these problems to the developer and wait  for a new release of the system.  • Bugs  are discovered and repaired more quickly than is usually possible with  proprietary software
• For a company involved in software development, there are two open - source issues that have to be  considered : 1. Should the product that is being developed make use of open - source components?  2. Should  an open - source approach be used for its own software  development The answers to these questions depend on the type of software that is being  developed  and the background  and experience of the development team . If you are developing a software product for sale, then time to market and reduced costs are critical.  If  you are developing software in a domain in which there are high - quality open - source systems available, you  can save time and money by using these systems.  However , if you are developing software to a specific set of organizational  requirements , then using open - source components may not be an option . You may have to integrate your software with existing systems that are incompatible with available pen - source  systems. Even then, however, it could be quicker and cheaper to modify the open - source system rather than  redevelop the functionality that you  need. Many software product companies are now using an open - source approach to  development , especially for  specialized systems
Open - source licensing • Although a fundamental principle of open - source development is that  source code should be freely available, this does not mean that anyone can  do as they wish with that code.  • Legally , the developer of the code (either a company or an individual) owns  the code . • They can place restrictions on how it is used by including legally binding  conditions in an open - source software license  . • Some  open - source developers believe that if an open - source component is  used to develop a new system, then that system should also be open  source.  • Others  are willing to allow their code to be used without this restriction.  • The  developed systems may be proprietary and sold as closed - source  systems
Open - source licensing • Most open - source licenses  are  variants of one of three general models:  1. The  GNU General Public License (GPL). This is a so - called reciprocal license that  simplistically means that if you use open - source software that is licensed under  the GPL license, then you must make that software open source.  2. The  GNU Lesser General Public License (LGPL). This is a variant of the GPL  license where you can write components that link to open - source code without  having to publish the source of these components. However, if you change the  licensed component, then you must publish this as open source.  3. The  Berkley Standard Distribution (BSD) License. This is a nonreciprocal license,  which means you are not obliged to re - publish any changes or modifications  made to open - source code. You can include the code in proprietary systems  that are sold. If you use open - source components, you must acknowledge the  original creator of the code. The MIT license is a variant of the BSD license with  similar conditions.
Open - source licensing • Licensing issues are important because if you use open - source software as  part of a software product, then you may be obliged by the terms of the  license to make your own product open source.  • If  you are trying to sell your software, you may wish to keep it secret. This  means that you may wish to avoid using GPL - licensed  open source  software in its development.  • If  you are building software that runs on an open - source platform but that  does not reuse open - source components, then licenses are not a problem.  • However , if you embed open - source software in your software, you need  processes and  databases  to keep track of what’s been used and their  license conditions
Open - source licensing companies managing projects that use open source should:  1. Establish  a system for maintaining information about open - source components that are downloaded and  used. You have to keep a copy of the license for each component that was valid at the time the  component was used. Licenses may change, so you need to know the conditions that you have agreed to.  2. Be aware of the different types of licenses and understand how a component is licensed before it is used.  You may decide to use a component in one system but not in another because you plan to use these  systems in different ways.  3. Be  aware of evolution pathways for components. You need to know a bit about the open - source project  where components are developed to understand how they might change in future.  4. Educate  people about open source. It’s not enough to have procedures in place to ensure compliance  with license conditions. You also need to educate  developers  about open source and open - source  licensing.  5. Have  auditing systems in place. Developers, under tight deadlines, might be tempted to break the terms  of a license. If possible, you should have software in place to detect and stop this.  6. Participate  in the open - source community. If you rely on open - source products, you should participate in  the community and help support their development.


SOFTWARE TESTING STRATEGIES A STRATEGIC APPROACH TO SOFTWARE TESTING
SOFTWARE TESTING STRATEGIES • A strategy for software testing provides a road map that describes the  steps to be conducted as part of testing, when these steps are  planned and then undertaken, and how much effort, time, and  resources will be required.  • Therefore, any testing strategy must incorporate test planning, test - case design, test execution, and resultant data collection and  evaluation. A software testing strategy should be flexible enough to  promote a customized testing approach.  • At the same time, it must be rigid enough to encourage reasonable  planning and management tracking as the project progresses
A STRATEGIC APPROACH TO  SOFTWARE TESTING Verification and Validation Organizing for Software Testing Software Testing Strategy — The Big Picture Criteria for Completion of Testing 
A STRATEGIC APPROACH TO SOFTWARE  TESTING • Testing is a set of activities that can be planned in advance and  conducted systematically. For this reason a template for software  testing — a set of steps into which we can place  specifi c test - case  design techniques and testing  methods — should be  defi ned for the  software process
A STRATEGIC APPROACH TO SOFTWARE  TESTING Generic characteristics of software testing strategies : • To perform effective testing, you should conduct effective technical  reviews. By doing this, many errors will be eliminated before testing  commences.  • Testing begins at the component level and works “outward” toward the  integration of the entire computer - based system.  • Different testing techniques are appropriate for different software  engineering approaches and at different points in time.  • Testing is conducted by the developer of the software and (for large  projects) an independent test group.  • Testing and debugging are different activities, but debugging must be  accommodated in any testing strategy. 
Verification and Validation • Software testing is one element of a broader topic that is often  referred to as verification and validation (V&V). • Verification refers to the set of tasks that ensure that software  correctly implements a specific function.  • Validation refers to a different set of tasks that ensure that the  software that has been built is traceable to customer requirements.  • Verification: “Are we building the product right?”  • Validation: “Are we building the right product?” 
Organizing for Software Testing   • The  software developer  is always responsible for testing the individual units  (components) of the program, ensuring that each performs the function or exhibits the  behavior for which it was designed.  • In many cases, the developer also conducts integration testing — a testing step that leads  to the construction (and test) of the complete software architecture.  • Only after the software architecture is complete does an independent test group become  involved.  • The role of an  independent test group (ITG)  is to remove the inherent problems  associated with letting the builder test the thing that has been built.  • Independent testing removes the conflict of interest that may otherwise be present.  • The developer and the ITG work closely throughout a software project to ensure that  thorough tests will be conducted.  • While testing is conducted, the developer must be available to correct errors that are  uncovered. 
Software Testing Strategy — The Big Picture
Software Testing Strategy — The Big Picture • Unit testing begins at the vortex of the spiral and concentrates on each unit  (e.g., component, class, or  WebApp content object) of the software as  implemented in source code.  • Testing progresses by moving outward along the spiral to integration  testing, where the focus is on design and the construction of the software  architecture.  • Taking another turn outward on the spiral, you encounter validation  testing, where requirements established as part of requirements modeling  are validated against the software that has been constructed.  • Finally, you arrive at system testing, where the software and other system  elements are tested as a whole.  • To test computer software, you spiral out along streamlines that broaden  the scope of testing with each turn. 

• “You're never done testing; the burden simply shifts from you (the  software engineer) to the end user.”  • Every time the user executes a computer program, the program is  being tested. • “You’re done testing when you run out of time or you run out of  money.”
TEST STRATEGIES FOR  CONVENTIONAL SOFTWARE Unit Testing 
Unit Testing • Unit testing focuses verification effort on the smallest unit of software  design — the software component or module. • Using the component - level design description as a guide, important  control paths are tested to uncover errors within the boundary of the  module.  • The relative complexity of tests and the errors those tests uncover is  limited by the constrained scope established for unit testing.  • The unit test focuses on the internal processing logic and data structures  within the boundaries of a component. • This type of testing can be conducted in parallel for multiple components. 
Unit Test Considerations. • The module interface is tested to ensure that information properly flows into and out of  the program unit under test.  • Local data structures are examined to ensure that data stored temporarily maintains its  integrity during all steps in an algorithm’s execution.  • All independent paths through the control structure are exercised to ensure that all  statements in a module have been executed at least once. • Boundary conditions are tested to ensure that the module operates properly at  boundaries established to limit or restrict processing.  • And finally, all error - handling paths are tested.  • Data flow across a component interface is tested before any other testing is initiated.  • If data do not enter and exit properly, all other tests are moot.  • In addition, local data structures should be exercised and the local impact on global data  should be ascertained (if possible) during unit testing.
Unit Test Considerations.
Unit - Test Procedures.  • The design of unit tests can occur before coding begins or after  source code has been generated.  • Each test case should be coupled with a set of expected results.  • Because a component is not a stand - alone program, driver and/or  stub software must often be developed for each unit test.  • The unit test environment is illustrated in Figure  • In most applications a driver is nothing more than a “main  program” that accepts test - case data, passes such data to the  component (to be tested), and prints relevant results. • Stubs serve to replace modules that are subordinate (invoked by)  the component to be tested.  • A stub or “dummy subprogram” uses the subordinate module’s  interface, may do minimal data manipulation, prints verification  of entry, and returns control to the module undergoing testing.  • Drivers and stubs represent testing “overhead.” That is, both are  software that must be coded (formal design is not commonly  applied) but that is not delivered with the final software product.  • If drivers and stubs are kept simple, actual overhead is relatively  low. Unfortunately, many components cannot be adequately unit  tested with “simple” overhead software. In such cases, complete  testing can be postponed until the integration test step (where  drivers or stubs are also used).
Integration Testing Top - Down Integration Bottom - Up Integration Regression Testing Smoke Testing
Integration Testing  • Integration testing is a systematic technique for constructing the software  architecture while at the same time conducting tests to uncover errors  associated with interfacing.  • The objective is to take unit - tested components and build a program  structure that has been dictated by design.  • Non incremental integration  - to construct the program using a “big bang”  approach. All components are combined in advance and the entire  program is tested as a whole. Errors are encountered, but correction is  difficult because isolation of causes is complicated by the vast expanse of  the entire program. • The program is constructed and tested in small increments, where errors  are easier to isolate and correct; interfaces are more likely to be tested  completely; and a systematic test approach may be applied. 
Top - Down Integration • .Top - down integration testing is an incremental approach to  construction of the software architecture. • Modules are integrated by moving downward through the control  hierarchy, beginning with the main control module (main program). • Modules subordinate (and ultimately subordinate) to the main  control module are incorporated into the structure in either a  depthfirst or breadth - first manner.
Top - Down Integration
Top - Down Integration 1. The main control module is used as a test driver and stubs are substituted  for all components directly subordinate to the main control module.  2. Depending on the integration approach selected (i.e., depth or breadth  first), subordinate stubs are replaced one at a time with actual components.  3. Tests are conducted as each component is integrated. 4. On completion of each set of tests, another stub is replaced with the real  component.  5. Regression testing (discussed later in this section) may be conducted to  ensure that new errors have not been introduced. 
• The top - down integration strategy verifies major control or decision  points early in the test process.
Bottom - Up Integration • Bottom - up integration testing, as its name implies, begins construction and testing with  atomic modules (i.e., components at the lowest levels in the program structure).  • Because components are integrated from the bottom up, the functionality provided by  components subordinate to a given level is always available and the need for stubs is  eliminated.  A bottom - up integration strategy may be implemented with the following steps:  1. Low - level components are combined into clusters (sometimes called builds) that  perform a specific software  subfunction . 2. A driver (a control program for testing) is written to coordinate test - case input and  output. 3. The cluster is tested.  4. Drivers are removed and clusters are combined moving upward in the program  structure.
Bottom - Up Integration.
Regression Testing • Each time a new module is added as part of integration testing, the  software changes.  • New data flow paths are established, new I/O may occur, and new control  logic is invoked. Side effects associated with these changes may cause  problems with functions that previously worked flawlessly. • In the context of an integration test strategy,  regression testing  is the  reexecution of some subset of tests that have already been conducted to  ensure that changes have not propagated unintended side effects. • Regression testing helps to ensure that changes (due to testing or for other  reasons) do not introduce unintended behavior or additional errors. 
Regression Testing • Regression testing may be conducted manually, by  reexecuting a subset of all test  cases or using automated capture/playback tools.  • Capture/playback tools enable the software engineer to capture test cases and  results for subsequent playback and comparison. The regression test suite (the subset of tests to be executed) contains three  different classes of test cases:  A representative sample of tests that will exercise all software functions.   Additional tests that focus on software functions that are likely to be affected by the change.   Tests that focus on the software components that have been changed. As integration testing proceeds, the number of regression tests can grow quite  large. Therefore, the regression test suite should be designed to include only those  tests that address one or more classes of errors in each of the major program  functions. 
Smoke Testing • Smoke testing is an integration testing approach that is commonly used when product software is  developed.  • It is designed as a pacing mechanism for time - critical projects, allowing the software team to assess the  project on a frequent basis.  In essence, the smoke - testing approach encompasses the following activities:  1. Software components that have been translated into code are integrated into a build. A build includes all  data files, libraries, reusable modules, and engineered components that are required to implement one or  more product functions.  2. A series of tests is designed to expose errors that will keep the build from properly performing its function.  3. The build is integrated with other builds, and the entire product (in its current form) is smoke tested daily. Smoke testing provides a number of  benefi ts when it is applied on complex, time - critical software projects:  • Integration risk is minimized • The quality of the end product is improved.  • Error diagnosis and correction are simplified.  • Progress is easier to assess. 
Validation testing • Validation testing begins at the culmination of integration testing,  when individual components have been exercised, the software is  completely assembled as a package, and interfacing errors have been  uncovered and corrected. • At the validation or system level, the distinction between different  software categories disappears. • Testing focuses on user - visible actions and user - recognizable output  from the system.  • Validation succeeds when software functions in a manner that can be  reasonably expected by the customer
Validation testing Validation - Test Criteria • Software validation is achieved through a series of tests that demonstrate conformity with  requirements.  • A test plan outlines the classes of tests to be conducted, and a test procedure defines specific test  cases that are designed to ensure that all functional requirements are satisfied, all behavioral  characteristics are achieved, all content is accurate and properly presented, all performance  requirements are attained, documentation is correct, and usability and other requirements are  met (e.g., transportability, compatibility, error recovery, maintainability).  • If a deviation from specification is uncovered, a deficiency list is created. • A method for resolving deficiencies (acceptable to stakeholders) must be established.  Configuration Review  • An important element of the validation process is a configuration review.  • The intent of the review is to ensure that all elements of the software configuration have been  properly developed, are cataloged, and have the necessary detail to bolster the support activities. • The  confi guration reviewis sometimes called an audit.
Validation testing • Alpha and Beta Testing • Most software  product builders use a process called alpha and beta testing to uncover errors that only the end user seems able to find.  Alpha Tests • The alpha test is conducted at the developer’s site by a representative group of end users. The software is used in a natural se tting with the developer  “looking over the shoulder” of the users and recording errors and usage problems.  • Alpha tests are conducted in a controlled environment.  Beta Tests • The beta test is conducted at one or more end - user sites • Unlike alpha testing, the developer generally is not present. Therefore, the beta test is a “live” application of the softwar e i n an environment that  cannot be controlled by the developer. The customer records all problems (real or imagined) that are encountered during beta  tes ting and reports  these to the developer at regular intervals.  • As a result of problems reported during beta tests, you make modifications and then prepare for release of the software produ ct  to the entire  customer base.  Customer Acceptance Testing • A variation on beta testing, called customer acceptance testing, is sometimes performed when custom software is delivered to  a c ustomer under  contract.  • The customer performs a series of specific tests in an attempt to uncover errors before accepting the software from the devel ope r. In some cases  (e.g., a major corporate or governmental system) acceptance testing can be very formal and encompass many days or even weeks  of  testing. 
SYSTEM TESTING • A classic system - testing problem is “finger pointing.” This occurs when an  error is uncovered, and the developers of different system elements blame  each other for the problem.  • Rather than indulging in such nonsense, you should anticipate potential  interfacing problems and  (1) design error - handling paths that test all information coming from other  elements of the system,  (2) conduct a series of tests that simulate bad data or other potential errors  at the software interface,  (3) record the results of tests to use as “evidence” if finger pointing does  occur, and  (4) participate in planning and design of system tests to ensure that software  is adequately tested.
SYSTEM TESTING Recovery testing • Recovery testing is a system test that forces the software to fail in a variety of ways and verifies  that recovery is properly performed.  • If recovery is automatic (performed by the system itself),  reinitialization ,  checkpointing mechanisms, data recovery, and restart are evaluated for correctness.  • If recovery requires human intervention, the mean - time - to - repair (MTTR) is evaluated to  determine whether it is within acceptable limits. Security testing • Security testing attempts to verify that protection mechanisms built into a system will, in fact,  protect it from improper penetration.  • “The system’s security must, of course, be tested for invulnerability from frontal attack — but  must also be tested for invulnerability from flank or rear attack.”  • Given enough time and resources, good security testing will ultimately penetrate a system.  • The role of the system designer is to make penetration cost more than the value of the  information that will be obtained
SYSTEM TESTING Stress Testing • Stress tests are designed to confront programs with abnormal situations.  • In essence, the tester who performs stress testing asks: “How high can we crank this up before it fails?” • Stress testing executes a system in a manner that demands resources in abnormal quantity, frequency, or  volume. • For example, (1) special tests may be designed that generate 10 interrupts per second, when one or two is  the average rate, (2) input data rates may be increased by an order of magnitude to determine how input  functions will respond, (3) test cases that require maximum memory or other resources are executed, (4)  test cases that may cause thrashing in a virtual operating system are designed, (5) test cases that may cause  excessive hunting for disk - resident data are created.  • Essentially, the tester attempts to break the program. • A variation of stress testing is a technique called  sensitivity testing.  In some situations (the most common  occur in mathematical algorithms), a very small range of data contained within the bounds of valid data for a  program may cause extreme and even erroneous processing or profound performance degradation.  • Sensitivity testing attempts to uncover data combinations within valid input classes that may cause  instability or improper processing
SYSTEM TESTING Performance Testing  • Performance testing is designed to test the run - time performance of software within the context  of an integrated system. • Performance testing occurs throughout all steps in the testing process. Even at the unit level, the  performance of an individual module may be assessed as tests are conducted. • However, it is not until all system elements are fully integrated that the true performance of a  system can be ascertained.  • Performance tests are often coupled with stress testing and usually require both hardware and  software instrumentation.  • That is, it is often necessary to measure resource utilization (e.g., processor cycles) in an exacting  fashion. • External instrumentation can monitor execution intervals, log events (e.g., interrupts) as they  occur, and sample machine states on a regular basis. • By instrumenting a system, the tester can uncover situations that lead to degradation and  possible system failure.
SYSTEM TESTING Deployment Testing • Deployment testing, sometimes called configuration testing, exercises  the software in each environment in which it is to operate. • In addition, deployment testing examines all installation procedures  and specialized installation software (e.g., “installers”) that will be  used by customers, and all documentation that will be used to  introduce the software to end users.
Debugging  The Debugging  Process Psychological  Considerations Debugging  Strategies Correcting the Error 
Debugging • Debugging occurs as a consequence of successful testing. That is,  when a test case uncovers an error, debugging is the process that  results in the removal of the error. 
The Debugging Process • The  debugging process begins with the execution of a test case . • Results are assessed and a lack of correspondence between expected and actual  performance is encountered . • In many cases, the  noncorresponding data are a symptom of an underlying cause  as yet hidden.  • The  debugging process attempts to match symptom with cause, thereby leading  to error correction.  • The  debugging process will usually have one of two outcomes : (1) the cause will be found and corrected or  ( 2) the cause will not be found . In the latter case, the person performing debugging may suspect a cause, design a  test case to help validate that suspicion, and work toward error correction in an  iterative fashion. 
The Debugging Process
The Debugging  Process Why is debugging so difficult? 1. The  symptom and the cause may be geographically remote.  2 . The symptom may disappear (temporarily) when another error is corrected.  3 . The symptom may actually be caused by  nonerrors (e.g., round - off inaccuracies ). 4 . The symptom may be caused by human error that is not easily traced.  5. The  symptom may be a result of timing problems, rather than processing problems.  6 . It may be  difficult  to accurately reproduce input conditions (e.g., a  real - time  application in which  input ordering is indeterminate).  7 . The symptom may be intermittent.  8 . The symptom may be due to causes that are distributed  across a number of tasks running on different processors . During debugging, we encounter errors that range from mildly annoying (e.g., an incorrect output  format) to catastrophic (e.g., the system fails, causing  serious economic or physical damage). As the  consequences of an error increase, the amount of pressure to fi  nd the cause also increases. 
Psychological Considerations • Debugging process  is an innate human trait. Some people are good at  it and others  aren’t. • Large variances  in debugging ability have been reported for  programmers with the same education and experience . 

Debugging Strategies Three  debugging strategies have been proposed  : • brute force • backtracking • cause  elimination.  Each  of these strategies can be  conducted  manually, but modern  debugging tools can make the process much more effective.
Debugging Strategies Brute force • The  brute force category of debugging is probably the most common and least  efficient  method for isolating the cause of a software error.  • You  apply brute force debugging methods when all else fails.  • Using  a “let the computer  find  the error” philosophy, memory dumps are taken, run - time traces are invoked, and the program is loaded with output  statements. You hope that somewhere in the morass of information that is produced you’ll  find  a clue that can lead us to the cause of an error.  • Although  the mass of information produced may ultimately lead to success, it more frequently leads to wasted effort and time.  Backtracking • Backtracking  is a fairly common debugging approach that can be used  successfully  in small programs.  • Beginning  at the site where a symptom has been  uncovered , the source code is traced backward (manually) until the cause is found.  • Unfortunately , as the number of source lines increases, the number of potential backward paths may become unmanageably large.  Cause  elimination • The  third approach to debugging — cause elimination — is manifested by  induction  or deduction and introduces the concept of binary partitioning.  • Data  related to the error occurrence are organized to isolate potential causes . • A “cause  hypothesis ” is devised and the aforementioned data are used to prove or disprove the hypothesis. Alternatively, a list of all possible  cau ses  is developed and tests are conducted to eliminate each . • If initial tests indicate that a particular cause hypothesis shows promise, data are  refined  in an attempt to isolate the bug. 
Debugging Strategies Automated Debugging • Each  of these debugging approaches can be  supplemented  with debugging  tools that can provide you with  semiautomated support as debugging  strategies are attempted.  • Integrated  development environments (IDEs) provide a way to capture  some of the  language - specific  predetermined errors (e.g., missing end - of - statement characters,  undefined  variables, and so on) without requiring  compilation .” • A wide variety of debugging compilers, dynamic debugging aids  (“tracers”),  automatic  test - case generators, and cross - reference mapping  tools are available.  • However , tools are not a substitute for careful evaluation based on a  complete design model and clear source code.
Debugging Strategies • The People Factor . Any  discussion of debugging approaches and tools is  incomplete  without mention of a powerful ally — other people!
Correcting the Error  • Once a bug has been found, it must be corrected.  • Three  simple questions that you should ask before making the  “correction” that removes the cause of a  bug. • Is the cause of the bug reproduced in another part of the program ? • What “next bug” might be introduced by the fi x I'm about to make ? • What could we have done to prevent this bug in the  first  place?
Testing • Once source code has been generated, software must be tested to  uncover (and correct) as many errors as possible before delivery to  your customer
SOFTWARE TESTING  FUNDAMENTALS • The goal of testing is to  find  errors, and a good test is one that has a high  probability  of  finding  an error. Therefore, you should design and implement  a computer - based system or a product with “testability” in mind.  • The  tests themselves  must exhibit a set of characteristics  that achieve the  goal of  finding  the most errors with a minimum of effort . • Testability . • Operability .  • Observability • Controllability.  • Decomposability.  • Simplicity .  • Stability .  • Understandability . 
Test Characteristics • A good test has a high probability of  finding  an error.  • A  good test is not redundant.  • A  good test should be “best of breed”  • A  good test should be neither too simple nor too complex. 
INTERNAL  AND EXTERNAL VIEWS OF TESTING • Any engineered product  can  be tested in one of two ways:  ( 1) Knowing the  specified  function that a product has been designed to  perform, tests can be conducted that demonstrate each function is fully  operational while at the same time searching for errors in each function.  ( 2) Knowing the internal workings of a product, tests can be conducted to  ensure that “all gears mesh,” that is, internal operations are performed  according to  specifications  and all internal components have been  adequately exercised.  • The first  test approach takes an external view and is called  black - box  testing . The second requires an internal view and is termed  white - box  testing. 
• Black - box testing  alludes to tests that are conducted at the  software  interface . A black - box test examines some fundamental aspect of a system with  little  regard for the internal  logical structure of the software . • White - box testing of software is predicated on close examination of procedural detail.  Logical paths through the software and collaborations between components are tested  by  exercising specific  sets of conditions and/or  loops. • At  first  glance it would seem that very thorough  white - box testing  would lead to “100  percent correct programs.” All we need do is  define  all logical paths, develop test cases  to exercise them, and evaluate results, that is, generate test cases to exercise program  logic exhaustively . • Unfortunately, exhaustive testing presents certain logistical problems. For even small  programs, the number of possible logical paths can be very large . • White - box testing should not, however, be dismissed as impractical.  A limited number  of important logical paths can be selected and exercised . Important data structures can  be probed for validity. 